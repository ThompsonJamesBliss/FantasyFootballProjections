---
title: "Fantasy Football"
author: "ThompsonBliss"
date: "August 19, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F)
```

```{r}
library(tidyverse)
library(dplyr)
library(ggrepel)

```

# Using Machine Learning to win my Fantasy Football Leagues
## By Thompson Bliss

## Section 1: Introduction

Due to growing numbers of websites and apps, as well as the greater fan interest, fantasy football participation has been increasing every year. According to Nielsen ratings, more than 15.5 million people played in a fantasy football in 2017. While many websites including [ESPN](https://fantasy.espn.com/football/players/projections), [YahooSports](https://sports.yahoo.com/2019-fantasy-football-rankings-taking-stock-at-every-position-142954685.html) and many others release projections and rankings from some of their football analysts, much of the projected points comes human perception rather than pure statistical modelling. Considering fantasy football has a scoring system based solely on player statistics, it may be interesting to see if a machine learning model can perform as well if not better than human football experts.

This project uses machine learning to predict a player's season points based on how the player has performed in previous years.

## Section 2: Proceedure
### Step 1 Acquiring the Data

Using the R package nflScrapR, player stats for each player in each game can be acquired using the 'season_player_game' command. The data is includes entries from 2009 - 2018. This data included the following statistics:

* Touchdowns
* Interceptions
* Fumbles
* Pass Yards
* Rush Yards
* Recieving Yards
* Pass Attempts
* Pass Completions
* Rush Attempts
* Receptions

Since the data did not include fantasy points, these were manually calculated using the weighted sum given by [ESPN](https://support.espn.com/hc/en-us/articles/360003914032-Scoring-Formats).

Additionally, their positions can be aquired using 'season_rosters'. The data is merged to get the position for each player.

### Step 2: Feature Creation

To increase accuracy of predictions, it is ideal to use more than just a player's raw stastics from the previous season. For each offensive statistic columns listed above, the following features are added:

| Feature | Description |
|-----------|-----------------------------------------------------------|
| Raw | Raw season-long value of offensive statistic from previous year |
| Per Game | Per Game value of offensive statistic from previous year |
| Var | Variance of offensive statistic per game from previous year |
| Career | Career value of offensive statistic for player up to previous year |
| Career Per Game | Career per game value of offensive statistic for player up to previous year |

In addition to these features, the following are created:

* Rush Yards per rush attempt
* Pass Yards per pass attempt
* Pass Yards per pass completion
* Recieving Yards per reception
* Rush TDs per rush attempt
* Pass TDs per pass attempt
* Pass TDs per pass completion
* Receiving TDs per reception
* Fumble per rush attempt
* Fumble per pass attempt
* Interception per pass attempt
* Fumble per reception
* Experience (years in league)
* Games played in previous season
* Total games played


Additionally, for each of these features, it is ideal to not only look at how each player individually performed, but how the team around him performed and how the team is changing. Additionally, schedule has a major impact on how a player performs. If they played an easy schedule, perhaps their numbers are artificially high. Conversely, if they played a difficult schedule, their numbers could be artificially low. To take all of this into account, for each feature listed above, the following features are added:

| Feature | Description |
|-----------|-----------------------------------------------------------|
| Previous Team | Team value of feature from previous year from team player was on previous year |
| Current Team | Team value of feature from previous year from team player is on current year |
| Delta Team | Difference in Team value of feature from previous year between previous team and current team |
| Previous Schedule | Sum of average value of feature allowed by opponents played in previous schedule |
| Current Schedule | Sum of average value of feature allowed by opponents played in current schedule |
| Delta Schedule | Difference in Sum of average value of feature allowed by opponents between current schedule and previous schedule |


### Step 3: Model Fitting

Using 'GridSearchCV' in 'sklearn', a variety of models with various paramaters are explored. The data is split into three sets: Training (Seasons 2009 - 2017), Validation (2018), Test (2019). The models are fit with the features as the independent variables and points as the dependent variable. They are tested with the least absolute deviations penalty. This penalty was chosen because RMSE penalizes larger penalties at quadratically greater rate than smaller penalties. Since there are breakout players or players who get injured who are bound to have stat lines far from what is predicted, RMSE would favor a model that more conservatively accounts for random events. The following models are tested:

* Linear Regression
* Lasso Regression
* Ridge Regression
* XgBoost Regression
* Random Forest Regression

The best linear model is Lasso Regression, while the best tree-based model is XgBoost.The top 10 coefficients / feature importances are shown in the chart below:

```{r}
df_coef_O_lin <- read_csv('output_coefs_O_linear.csv') %>% head(10) %>% select(value)

df_coef_O_lin <- df_coef_O_lin %>% mutate(name = c("Career Rush Yards\nPer Game\nUp to Previous Season",
                                  "Career Recieving Yards\nPer Game\nUp to Previous Season",
                                  "Fantasy Points Previous Season",
                                  "Rush Yards Per Game Previous Season",
                                  "Variance of Pass TDs thrown Previous Season",
                                  "Career Fantasy Points up to Previous Season",
                                  "Recieving Yards Previous Season",
                                  "Team Receptions Previous Season For Previous Team",
                                  "Career Rush Yards\nPer Game\nUp to Previous Season",
                                  "Difference in Team Punt Returns\nBetween Previous and Current Teams"))

ggplot(df_coef_O_lin, aes(y = value, x = name)) + geom_bar(stat = "Identity") + theme_bw()

df_coef_O_tree <- read_csv('output_coefs_O_tree.csv') %>% head(15)



```


```{r}
#loading data
df_results_2018_lin <- read_csv('results_2018_linear.csv')
df_results_2019_lin <- read_csv('results_2019_linear.csv')
df_results_2018_tree <- read_csv('results_2018_tree.csv')
df_results_2019_tree <- read_csv('results_2019_tree.csv')
df_coef_O_lin <- read_csv('output_coefs_O_linear.csv')
df_coef_D_lin <- read_csv('output_coefs_D_linear.csv')
df_coef_O_tree <- read_csv('output_coefs_O_tree.csv')
df_coef_D_tree <- read_csv('output_coefs_D_tree.csv')

```

```{r}

df_plot <- data.frame(linear_error = abs(df_results_2018_lin$actual_points - df_results_2018_lin$predicted_points), tree_error = abs(df_results_2018_tree$actual_points - df_results_2018_tree$predicted_points)) 

df_plot_text <- data.frame(error_type = c("Linear", "Tree"), error = c(mean(df_plot$linear_error),
                                                                  mean(df_plot$tree_error)))

df_plot <- df_plot %>% gather(key = "error_type", value = "error", c("linear_error", "tree_error"))

df_plot <- df_plot %>% group_by(error_type) %>% mutate(mean_val = mean(error)) %>% ungroup()

ggplot(df_plot, aes(error, color = error_type)) + geom_density(alpha=0.25) + xlim(0,150) + theme_bw() +
  geom_text_repel(aes(label = mean_val), y = 0.2)

```


```{r}

df_coef_O_tree
```


https://www.nielsen.com/us/en/insights/article/2018/fantasy-is-reality-a-look-at-growing-engagement-in-fantasy-sports/