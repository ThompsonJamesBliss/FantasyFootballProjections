{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019 Fantasy Football Projections based on 2009-18 statistics.\n",
    "\n",
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_columns_stats = [\"Season\", \"playerID\", \"game.id\", \"Team\", \"name\", \"pass.att\", \"pass.comp\",\n",
    "                    \"passyds\", \"pass.tds\", \"pass.ints\", \"rush.att\", \"rushyds\",\n",
    "                    \"rushtds\", \"recyds\", \"rec.tds\", \"recept\", \"kickret.avg\",\n",
    "                   \"kickret.tds\", \"kick.rets\", \"punt.rets\", \"puntret.avg\", \n",
    "                   \"puntret.tds\", \"fgm\", \"fga\", \"fgyds\", \"xpmade\", \"xpmissed\",\n",
    "                   \"sacks\", 'defints', \"forced.fumbs\", \"totalfumbs\", \"recfumbs\", \"pass.twoptm\",\n",
    "                   \"fumbslost\", \"rec.twoptm\", \"rush.twoptm\"]\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(\"2009stats.csv\", usecols = relevant_columns_stats)\n",
    "df_train = df_train.append(pd.read_csv(\"2010stats.csv\", usecols = relevant_columns_stats))\n",
    "df_train = df_train.append(pd.read_csv(\"2011stats.csv\", usecols = relevant_columns_stats))\n",
    "df_train = df_train.append(pd.read_csv(\"2012stats.csv\", usecols = relevant_columns_stats))\n",
    "df_train = df_train.append(pd.read_csv(\"2013stats.csv\", usecols = relevant_columns_stats))\n",
    "df_train = df_train.append(pd.read_csv(\"2014stats.csv\", usecols = relevant_columns_stats))\n",
    "df_train = df_train.append(pd.read_csv(\"2015stats.csv\", usecols = relevant_columns_stats))\n",
    "df_train = df_train.append(pd.read_csv(\"2016stats.csv\", usecols = relevant_columns_stats))\n",
    "df_train = df_train.append(pd.read_csv(\"2017stats.csv\", usecols = relevant_columns_stats))\n",
    "df_train = df_train.append(pd.read_csv(\"2018stats.csv\", usecols = relevant_columns_stats))\n",
    "df_train.Team = df_train.Team.replace(\"STL\",\"LA\")\n",
    "df_train.Team = df_train.Team.replace(\"SD\",\"LAC\")\n",
    "df_train.Team = df_train.Team.replace(\"JAC\",\"JAX\")\n",
    "\n",
    "\n",
    "df_train.dropna(inplace = True)\n",
    "\n",
    "relevant_columns_def = [\"Tm\",\"PR TD\",\"KR TD\",\"FblTD\",\"IntTD\",\"OthTD\",\"Sfty\"]\n",
    "\n",
    "relevant_columns_def = [\"Tm\",\"PR TD\",\"KR TD\",\"FblTD\",\"IntTD\",\"OthTD\",\"Sfty\"]\n",
    "\n",
    "df_def = pd.read_csv(\"2009def.csv\", usecols = relevant_columns_def)\n",
    "df_def = df_def.append(pd.read_csv(\"2010def.csv\", usecols = relevant_columns_def))\n",
    "df_def = df_def.append(pd.read_csv(\"2011def.csv\", usecols = relevant_columns_def))\n",
    "df_def = df_def.append(pd.read_csv(\"2012def.csv\", usecols = relevant_columns_def))\n",
    "df_def = df_def.append(pd.read_csv(\"2013def.csv\", usecols = relevant_columns_def))\n",
    "df_def = df_def.append(pd.read_csv(\"2014def.csv\", usecols = relevant_columns_def))\n",
    "df_def = df_def.append(pd.read_csv(\"2015def.csv\", usecols = relevant_columns_def))\n",
    "df_def = df_def.append(pd.read_csv(\"2016def.csv\", usecols = relevant_columns_def))\n",
    "df_def = df_def.append(pd.read_csv(\"2017def.csv\", usecols = relevant_columns_def))\n",
    "df_def = df_def.append(pd.read_csv(\"2018def.csv\", usecols = relevant_columns_def))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Attributes for Opposition and Making Way to Merge Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_def[\"sum_vals\"] = 1\n",
    "\n",
    "df_abbreviations = pd.read_csv(\"abbreviations.csv\")\n",
    "\n",
    "df_def = df_def.merge(df_abbreviations, on = [\"Tm\"])\n",
    "\n",
    "\n",
    "df_def[\"Season\"] = df_def.groupby(\"Team\")[\"sum_vals\"].transform(lambda x: x.cumsum() + 2008)\n",
    "\n",
    "df_def.fillna(0, inplace = True)\n",
    "\n",
    "df_def.drop([\"Tm\", \"sum_vals\"], inplace = True, axis = 1)\n",
    "\n",
    "df_train['opp'] = df_train.groupby(\"game.id\").Team.transform(lambda x: x.unique()[0])\n",
    "df_train['opp2'] = df_train.groupby(\"game.id\").Team.transform(lambda x: x.unique()[1])\n",
    "\n",
    "df_train.loc[df_train['opp'] == df_train['Team'], 'opp'] = df_train.loc[df_train['opp'] == df_train['Team'], 'opp2']\n",
    "df_train.drop(['opp2'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_columns_pos = [\"GSIS_ID\", \"Season\", \"Pos\"]\n",
    "\n",
    "df_pos = pd.read_csv(\"2009Pos.csv\", usecols = relevant_columns_pos)\n",
    "df_pos = df_pos.append(pd.read_csv(\"2010Pos.csv\", usecols = relevant_columns_pos))\n",
    "df_pos = df_pos.append(pd.read_csv(\"2011Pos.csv\", usecols = relevant_columns_pos))\n",
    "df_pos = df_pos.append(pd.read_csv(\"2012Pos.csv\", usecols = relevant_columns_pos))\n",
    "df_pos = df_pos.append(pd.read_csv(\"2013Pos.csv\", usecols = relevant_columns_pos))\n",
    "df_pos = df_pos.append(pd.read_csv(\"2014Pos.csv\", usecols = relevant_columns_pos))\n",
    "df_pos = df_pos.append(pd.read_csv(\"2015Pos.csv\", usecols = relevant_columns_pos))\n",
    "df_pos = df_pos.append(pd.read_csv(\"2016Pos.csv\", usecols = relevant_columns_pos))\n",
    "df_pos = df_pos.append(pd.read_csv(\"2017Pos.csv\", usecols = relevant_columns_pos))\n",
    "df_pos = df_pos.append(pd.read_csv(\"2018Pos.csv\", usecols = relevant_columns_pos))\n",
    "\n",
    "df_pos.Pos = df_pos.Pos.replace(\"FB\",\"RB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating Data into Offense and Defense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_columns = [\"Team\",\"rec.twoptm\",\n",
    "              \"passyds\", \"pass.tds\", \"rushyds\",\n",
    "              \"rushtds\", \"kickret.tds\", \"puntret.tds\", \"fgm\",\n",
    "              \"xpmade\", \"fumbslost\", \"pass.ints\",\n",
    "              \"rush.twoptm\"]\n",
    "\n",
    "df_defense = df_train\n",
    "\n",
    "df_defense[\"points_allowed\"] = ((df_defense[\"pass.tds\"] + df_defense[\"rushtds\"] + df_defense[\"kickret.tds\"]\n",
    "                                 + df_defense[\"puntret.tds\"]) * 6 + df_defense[\"fgm\"] * 3 +\n",
    "                                df_defense[\"rec.twoptm\"] * 2 + df_defense[\"rush.twoptm\"] * 2\n",
    "                                + df_defense[\"xpmade\"])\n",
    "\n",
    "df_defense[\"yards\"] = df_defense[\"passyds\"] + df_defense[\"rushyds\"]\n",
    "\n",
    "df_defense = df_defense.groupby([\"game.id\",\"opp\", \"Season\",])[\"yards\", \"points_allowed\"].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_defense[\"0pts\"] = df_defense.points_allowed == 0\n",
    "df_defense[\"1_6pts\"] = df_defense.points_allowed.between(1, 6)\n",
    "df_defense[\"7_13pts\"] = df_defense.points_allowed.between(7, 13)\n",
    "df_defense[\"14_17pts\"] = df_defense.points_allowed.between(14, 17)\n",
    "df_defense[\"18_27pts\"] = df_defense.points_allowed.between(18, 27)\n",
    "df_defense[\"28_34pts\"] = df_defense.points_allowed.between(28, 34)\n",
    "df_defense[\"35_45pts\"] = df_defense.points_allowed.between(35, 45)\n",
    "df_defense[\"45pts\"] = df_defense.points_allowed > 45\n",
    "\n",
    "df_defense[\"YA100\"] = df_defense.yards < 100\n",
    "df_defense[\"YA199\"] = df_defense.yards.between(100, 199)\n",
    "df_defense[\"YA299\"] = df_defense.yards.between(200, 299)\n",
    "df_defense[\"YA349\"] = df_defense.yards.between(300, 349)\n",
    "df_defense[\"YA399\"] = df_defense.yards.between(350, 399)\n",
    "df_defense[\"YA449\"] = df_defense.yards.between(400, 449)\n",
    "df_defense[\"YA499\"] = df_defense.yards.between(450, 499)\n",
    "df_defense[\"YA549\"] = df_defense.yards.between(500, 549)\n",
    "df_defense[\"YA550\"] = df_defense.yards > 549"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_columns = [\"0pts\", \"1_6pts\", \"7_13pts\", \"14_17pts\",\n",
    "               \"28_34pts\",\"35_45pts\",\"45pts\",\n",
    "               \"YA100\",\"YA199\",\"YA299\",\"YA399\",\n",
    "               \"YA449\",\"YA499\",\"YA549\",\"YA550\", \"YA349\", \"18_27pts\"]\n",
    "\n",
    "\n",
    "df_defense = df_defense.groupby([\"Season\", \"opp\"])[def_columns].sum()\n",
    "\n",
    "\n",
    "\n",
    "df_defense[\"Sacks\"] = df_train.groupby([\"Season\", \"Team\"])[\"sacks\"].sum()\n",
    "\n",
    "df_train[\"exp\"] = df_train.groupby(\"playerID\").Season.transform(lambda x: x - min(x))\n",
    "\n",
    "df_defense[\"exp\"] = df_train.groupby([\"Season\", \"Team\"])[\"exp\"].mean()\n",
    "\n",
    "df_train.drop(\"exp\", inplace = True, axis = 1)\n",
    "\n",
    "df_defense[\"pass.ints\"] = df_train.groupby([\"Season\", \"opp\"])[\"pass.ints\"].sum()\n",
    "\n",
    "df_defense[\"fumbslost\"] = df_train.groupby([\"Season\", \"opp\"])[\"fumbslost\"].sum()\n",
    "\n",
    "df_defense[\"rush_per_att\"] = (df_train.groupby([\"Season\", \"opp\"])[\"rushyds\"].sum() / \n",
    "                                df_train.groupby([\"Season\", \"opp\"])[\"rush.att\"].sum())\n",
    "\n",
    "df_defense[\"td_rush_per_att\"] = (df_train.groupby([\"Season\", \"opp\"])[\"rushtds\"].sum() / \n",
    "                                df_train.groupby([\"Season\", \"opp\"])[\"rush.att\"].sum())\n",
    "\n",
    "df_defense[\"rec_per_att\"] = (df_train.groupby([\"Season\", \"opp\"])[\"recyds\"].sum() / \n",
    "                                df_train.groupby([\"Season\", \"opp\"])[\"recept\"].sum())\n",
    "\n",
    "df_defense[\"td_rec_per_att\"] = (df_train.groupby([\"Season\", \"opp\"])[\"rec.tds\"].sum() / \n",
    "                                df_train.groupby([\"Season\", \"opp\"])[\"recept\"].sum())\n",
    "\n",
    "df_defense[\"pass_per_att\"] = (df_train.groupby([\"Season\", \"opp\"])[\"passyds\"].sum() / \n",
    "                                df_train.groupby([\"Season\", \"opp\"])[\"pass.att\"].sum())\n",
    "\n",
    "df_defense[\"td_pass_per_att\"] = (df_train.groupby([\"Season\", \"opp\"])[\"pass.tds\"].sum() / \n",
    "                                df_train.groupby([\"Season\", \"opp\"])[\"pass.att\"].sum())\n",
    "\n",
    "df_defense[\"pass_per_comp\"] = (df_train.groupby([\"Season\", \"opp\"])[\"passyds\"].sum() / \n",
    "                                df_train.groupby([\"Season\", \"opp\"])[\"pass.comp\"].sum())\n",
    "\n",
    "df_defense[\"td_pass_per_comp\"] = (df_train.groupby([\"Season\", \"opp\"])[\"pass.tds\"].sum() / \n",
    "                                df_train.groupby([\"Season\", \"opp\"])[\"pass.comp\"].sum())\n",
    "\n",
    "df_defense = df_defense.merge(df_def, left_on = [\"opp\", \"Season\"], right_on = [\"Team\", \"Season\"])\n",
    "\n",
    "df_defense[\"TD\"] = (df_defense[\"PR TD\"] + df_defense[\"KR TD\"] + df_defense[\"FblTD\"] + df_defense[\"IntTD\"] +\n",
    "+df_defense[\"OthTD\"])\n",
    "\n",
    "df_defense[\"turnovers\"] = df_defense[\"fumbslost\"] + df_defense[\"pass.ints\"]\n",
    "\n",
    "df_defense.drop([\"fumbslost\", \"pass.ints\", \n",
    "            \"PR TD\",\"KR TD\",\"FblTD\",\"IntTD\",\"OthTD\"], axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "df_defense_scores = (df_defense[\"TD\"]*6 + df_defense[\"turnovers\"] * 2 + df_defense[\"Sacks\"] + df_defense[\"Sfty\"] * 2 +\n",
    "                    (df_defense[\"0pts\"] + df_defense[\"YA100\"]) * 5 + \n",
    "                    df_defense['1_6pts'] * 4 +\n",
    "                    (df_defense[\"7_13pts\"] + df_defense[\"YA199\"]) * 3 +\n",
    "                     df_defense[\"YA299\"] * 2 +\n",
    "                    df_defense[\"14_17pts\"] +\n",
    "                    (df_defense[\"YA399\"] + df_defense[\"28_34pts\"]) * (-1) +\n",
    "                    (df_defense[\"YA449\"] + df_defense[\"35_45pts\"]) * (-3) +\n",
    "                    (df_defense[\"YA499\"] + df_defense[\"45pts\"]) * (-5) +\n",
    "                    (df_defense[\"YA549\"]) * (-6) +\n",
    "                    (df_defense[\"YA550\"]) * (-7)).to_frame()\n",
    "\n",
    "off_columns = [\"Season\", \"playerID\", \"game.id\", \"Team\", \"name\", \"pass.att\", \"pass.comp\",\n",
    "                    \"passyds\", \"pass.tds\", \"pass.ints\", \"rush.att\", \"rushyds\",\n",
    "                    \"rushtds\", \"recyds\", \"rec.tds\", \"recept\", \"kickret.avg\",\n",
    "                   \"kickret.tds\", \"kick.rets\", \"punt.rets\", \"puntret.avg\", \n",
    "                   \"puntret.tds\", \"fumbslost\", \"rec.twoptm\", \"rush.twoptm\", \"pass.twoptm\",\n",
    "              \"fgm\", \"fga\", \"fgyds\", \"xpmade\", \"xpmissed\", \"totalfumbs\", \"opp\"]\n",
    "\n",
    "off_columns_numeric = [\"pass.att\", \"pass.comp\", \"totalfumbs\", \"fumbslost\",\n",
    "                    \"passyds\", \"pass.tds\", \"pass.ints\", \"rush.att\", \"rushyds\",\n",
    "                    \"rushtds\", \"recyds\", \"rec.tds\", \"recept\", \"kickret.avg\",\n",
    "                   \"kickret.tds\", \"kick.rets\", \"punt.rets\", \"puntret.avg\", \n",
    "                   \"puntret.tds\", \"rec.twoptm\", \"rush.twoptm\", \"pass.twoptm\",\n",
    "                      \"fgm\", \"fga\", \"fgyds\", \"xpmade\", \"xpmissed\"]\n",
    "\n",
    "\n",
    "\n",
    "df_offense = df_train[off_columns]\n",
    "\n",
    "\n",
    "df_offense = pd.merge(df_offense, df_pos, left_on = [\"playerID\", \"Season\"], \n",
    "                      right_on = [\"GSIS_ID\", \"Season\"], how = \"left\").drop(\"GSIS_ID\", axis = 1)\n",
    "\n",
    "df_offense.Pos = df_offense.groupby(\"playerID\").Pos.fillna(method = 'ffill')\n",
    "df_offense.Pos = df_offense.groupby(\"playerID\").Pos.fillna(method = 'bfill')\n",
    "\n",
    "df_offense = df_offense.dropna(subset = [\"Pos\"])\n",
    "\n",
    "\n",
    "\n",
    "df_offense['n_games'] = df_offense.groupby(['playerID', 'Season'])['game.id'].transform(lambda x: len(x.unique()))\n",
    "\n",
    "\n",
    "df_offense[\"points\"] = (df_offense[\"passyds\"] * 0.025 + 4 * df_offense[\"pass.tds\"] - 2 * df_offense[\"pass.ints\"]\n",
    "                       + 0.1 * df_offense[\"rushyds\"] + 6 * df_offense[\"rushtds\"] + 0.1 * df_offense[\"recyds\"] +\n",
    "                        6 * df_offense[\"rec.tds\"] + 6 * df_offense[\"kickret.tds\"] + 6 * df_offense[\"puntret.tds\"]\n",
    "                       + 2 * df_offense[\"rec.twoptm\"] + 2 * df_offense[\"rush.twoptm\"] + 2 * df_offense[\"pass.twoptm\"]\n",
    "                       + 4 * df_offense[\"fgm\"] - df_offense[\"fga\"] + \n",
    "                        df_offense[\"xpmade\"] - 2 * df_offense[\"fumbslost\"])\n",
    "\n",
    "off_columns_numeric.append('points')\n",
    "\n",
    "off_columns_numeric_no_avg = off_columns_numeric.copy()\n",
    "\n",
    "\n",
    "for col in off_columns_numeric_no_avg:\n",
    "    df_offense[col + '_per_game'] = df_offense[col] / df_offense['n_games']\n",
    "    \n",
    "    df_offense[col + '_var'] = ((df_offense[col] - \n",
    "                                 df_offense.groupby([\"Season\", \"playerID\"])[col + '_per_game'].transform(lambda x: sum(x))\n",
    "                                ) ** 2/df_offense['n_games'])\n",
    "    \n",
    "    df_offense[col + '_var'] = ((df_offense[col] - \n",
    "                                 df_offense.groupby([\"playerID\"])[col + '_per_game'].transform(lambda x: sum(x))\n",
    "                                ) ** 2/df_offense['n_games'])\n",
    "    \n",
    "    off_columns_numeric.append(col + '_per_game')\n",
    "    off_columns_numeric.append(col + '_var')\n",
    "\n",
    "\n",
    "off_columns_numeric.append('n_games')\n",
    "\n",
    "\n",
    "\n",
    "df_offense.Team = df_offense.groupby([\"Season\", \"playerID\"]).Team.transform(lambda x: x.iloc[len(x) - 1])\n",
    "\n",
    "df_offense = pd.merge(df_offense.groupby([\"Season\", \"playerID\", \"Team\"])[off_columns_numeric].sum().reset_index(),\n",
    "                      df_offense[[\"playerID\", \"name\"]].drop_duplicates(\"playerID\", keep = \"last\"), on = \"playerID\")\n",
    "\n",
    "\n",
    "df_offense['n_games'] = np.sqrt(df_offense['n_games'])\n",
    "\n",
    "df_offense[\"points\"] = (df_offense[\"passyds\"] * 0.025 + 4 * df_offense[\"pass.tds\"] - 2 * df_offense[\"pass.ints\"]\n",
    "                       + 0.1 * df_offense[\"rushyds\"] + 6 * df_offense[\"rushtds\"] + 0.1 * df_offense[\"recyds\"] +\n",
    "                        6 * df_offense[\"rec.tds\"] + 6 * df_offense[\"kickret.tds\"] + 6 * df_offense[\"puntret.tds\"]\n",
    "                       + 2 * df_offense[\"rec.twoptm\"] + 2 * df_offense[\"rush.twoptm\"] + 2 * df_offense[\"pass.twoptm\"]\n",
    "                       + 4 * df_offense[\"fgm\"] - df_offense[\"fga\"] + \n",
    "                        df_offense[\"xpmade\"] - 2 * df_offense[\"fumbslost\"])\n",
    "\n",
    "\n",
    "\n",
    "df_offense['total_games'] = df_offense.groupby([\"playerID\"])['n_games'].transform(lambda x: np.cumsum(x))\n",
    "\n",
    "off_columns_numeric.append('total_games')\n",
    "\n",
    "for col in off_columns_numeric_no_avg:\n",
    "    df_offense[col + \"_career\"] = df_offense.groupby([\"playerID\"])[col].transform(lambda x: np.cumsum(x))\n",
    "    \n",
    "    df_offense[col + \"_career_per_game\"] = df_offense.groupby([\"playerID\"])[col].transform(lambda x: \n",
    "                                                                                           np.cumsum(x))/df_offense['total_games']\n",
    "\n",
    "    off_columns_numeric.append(col + \"_career\")\n",
    "    \n",
    "    off_columns_numeric.append(col + \"_career_per_game\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_offense['rush_per_att'] = (df_offense['rushyds'] / df_offense['rush.att']).fillna(0)\n",
    "df_offense['rush_per_att'].loc[df_offense['rush_per_att'] == np.inf] = 0\n",
    "off_columns_numeric.append('rush_per_att')\n",
    "\n",
    "df_offense['pass_per_att'] = (df_offense['passyds'] / df_offense['pass.att']).fillna(0)\n",
    "df_offense['pass_per_att'].loc[df_offense['pass_per_att'] == np.inf] = 0\n",
    "off_columns_numeric.append('pass_per_att')\n",
    "\n",
    "\n",
    "df_offense['pass_per_comp'] = (df_offense['passyds'] / df_offense['pass.comp']).fillna(0)\n",
    "df_offense['pass_per_comp'].loc[df_offense['pass_per_comp'] == np.inf] = 0\n",
    "off_columns_numeric.append('pass_per_comp')\n",
    "\n",
    "\n",
    "df_offense['rec_per_att'] = (df_offense['recyds'] / df_offense['recept']).fillna(0)\n",
    "df_offense['rec_per_att'].loc[df_offense['rec_per_att'] == np.inf] = 0\n",
    "off_columns_numeric.append('rec_per_att')\n",
    "\n",
    "df_offense['td_rush_per_att'] = (df_offense['rushtds'] / df_offense['rush.att']).fillna(0)\n",
    "df_offense['td_rush_per_att'].loc[df_offense['td_rush_per_att'] == np.inf] = 0\n",
    "off_columns_numeric.append('td_rush_per_att')\n",
    "\n",
    "df_offense['td_pass_per_att'] = (df_offense['pass.tds'] / df_offense['pass.att']).fillna(0)\n",
    "df_offense['td_pass_per_att'].loc[df_offense['td_pass_per_att'] == np.inf] = 0\n",
    "off_columns_numeric.append('td_pass_per_att')\n",
    "\n",
    "\n",
    "df_offense['td_pass_per_comp'] = (df_offense['pass.tds'] / df_offense['pass.comp']).fillna(0)\n",
    "df_offense['td_pass_per_comp'].loc[df_offense['td_pass_per_comp'] == np.inf] = 0\n",
    "off_columns_numeric.append('td_pass_per_comp')\n",
    "\n",
    "\n",
    "df_offense['td_rec_per_att'] = (df_offense['rec.tds'] / df_offense['recept']).fillna(0)\n",
    "df_offense['td_rec_per_att'].loc[df_offense['td_rec_per_att'] == np.inf] = 0\n",
    "off_columns_numeric.append('td_rec_per_att')\n",
    "\n",
    "\n",
    "df_offense['fumb_rush_per_att'] = (df_offense['totalfumbs'] / df_offense['rush.att']).fillna(0)\n",
    "df_offense['fumb_rush_per_att'].loc[df_offense['fumb_rush_per_att'] == np.inf] = 0\n",
    "off_columns_numeric.append('fumb_rush_per_att')\n",
    "\n",
    "df_offense['fumb_pass_per_att'] = (df_offense['totalfumbs'] / df_offense['pass.att']).fillna(0)\n",
    "df_offense['fumb_pass_per_att'].loc[df_offense['fumb_pass_per_att'] == np.inf] = 0\n",
    "off_columns_numeric.append('fumb_pass_per_att')\n",
    "\n",
    "df_offense['int_pass_per_att'] = (df_offense['pass.ints'] / df_offense['pass.att']).fillna(0)\n",
    "df_offense['int_pass_per_att'].loc[df_offense['int_pass_per_att'] == np.inf] = 0\n",
    "off_columns_numeric.append('int_pass_per_att')\n",
    "\n",
    "df_offense['fumb_per_rec'] = (df_offense['totalfumbs'] / df_offense['recept']).fillna(0)\n",
    "df_offense['fumb_per_rec'].loc[df_offense['fumb_per_rec'] == np.inf] = 0\n",
    "off_columns_numeric.append('fumb_per_rec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding data for previous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_offense = pd.merge(df_offense, df_pos, left_on = [\"playerID\", \"Season\"], \n",
    "                      right_on = [\"GSIS_ID\", \"Season\"], how = \"left\").drop(\"GSIS_ID\", axis = 1)\n",
    "\n",
    "df_offense.Pos = df_offense.groupby(\"playerID\").Pos.fillna(method = 'ffill')\n",
    "df_offense.Pos = df_offense.groupby(\"playerID\").Pos.fillna(method = 'bfill')\n",
    "\n",
    "relevant_prev_columns = off_columns_numeric.copy()\n",
    "\n",
    "relevant_columns_spotrac = ['PLAYER', 'POS', 'TEAM']\n",
    "\n",
    "df_spotrac = pd.read_csv(\"Spotrac_NFLActivePlayerContracts.csv\", encoding = \"ISO-8859-1\",\n",
    "                        usecols = relevant_columns_spotrac)\n",
    "\n",
    "df_spotrac = df_spotrac.loc[df_spotrac.POS != 'OLB']\n",
    "df_spotrac = df_spotrac.loc[df_spotrac.POS != 'DT']\n",
    "df_spotrac = df_spotrac.loc[df_spotrac.POS != 'DE']\n",
    "df_spotrac = df_spotrac.loc[df_spotrac.POS != 'LT']\n",
    "df_spotrac = df_spotrac.loc[df_spotrac.POS != 'ILB']\n",
    "df_spotrac = df_spotrac.loc[df_spotrac.POS != 'G']\n",
    "df_spotrac = df_spotrac.loc[df_spotrac.POS != 'FS']\n",
    "df_spotrac = df_spotrac.loc[df_spotrac.POS != 'CB']\n",
    "df_spotrac = df_spotrac.loc[df_spotrac.POS != 'RT']\n",
    "df_spotrac = df_spotrac.loc[df_spotrac.POS != 'SS']\n",
    "df_spotrac = df_spotrac.loc[df_spotrac.POS != 'C']\n",
    "df_spotrac = df_spotrac.loc[df_spotrac.POS != 'P']\n",
    "df_spotrac = df_spotrac.loc[df_spotrac.POS != 'LB']\n",
    "df_spotrac = df_spotrac.loc[df_spotrac.POS != 'T']\n",
    "df_spotrac = df_spotrac.loc[df_spotrac.POS != 'S']\n",
    "df_spotrac = df_spotrac.loc[df_spotrac.POS != 'LS']\n",
    "\n",
    "df_spotrac.PLAYER = df_spotrac.PLAYER.transform(lambda x: x.str.split('\\xa0').str.get(0))\n",
    "df_spotrac.PLAYER = df_spotrac.PLAYER.transform(lambda x: x.str.split(' ').str.get(0).str[0] + '.' + \n",
    "                                         x.str.split(' ').str.get(-1))\n",
    "\n",
    "df_spotrac.TEAM = df_spotrac.TEAM.transform(lambda x: x.str.split('Signed').str.get(0))\n",
    "df_spotrac.rename(columns={\"PLAYER\": \"name\", \"TEAM\": \"next_Team\", \"POS\": \"Pos\"}, inplace = True)\n",
    "\n",
    "df_spotrac.loc[df_spotrac.name == \"O.Jr.\", \"name\"] = \"O.Beckham\"\n",
    "df_spotrac.loc[df_spotrac.name == \"T.Jr.\", \"name\"] = \"T.Ginn\"\n",
    "\n",
    "df_spotrac[\"name_dict\"] = df_spotrac[\"name\"] + \"_\" + df_spotrac[\"Pos\"]\n",
    "\n",
    "df_offense.sort_values([\"Season\", \"Team\"], inplace = True)\n",
    "df_offense.reset_index(inplace = True, drop = True)\n",
    "\n",
    "df_offense[\"name_dict\"] = df_offense[\"name\"] + \"_\" + df_offense[\"Pos\"]\n",
    "\n",
    "df_offense[\"next_Team\"] = df_offense.groupby(\"playerID\").Team.transform(lambda x: x.shift(-1))\n",
    "df_offense[\"prev_Team\"] = df_offense.groupby(\"playerID\").Team.transform(lambda x: x.shift())\n",
    "df_offense.next_Team = df_offense.set_index(\"name_dict\").next_Team.fillna(\n",
    "    df_spotrac.reindex(index=df_spotrac.index[::-1]).set_index(\"name_dict\").to_dict()[\"next_Team\"]).tolist()\n",
    "\n",
    "df_offense[\"next_Season\"] = df_offense.Season + 1\n",
    "\n",
    "df_offense_2019 = df_offense.loc[df_offense.Season == 2018]\n",
    "\n",
    "df_offense_2019[list(set(df_offense_2019.columns) - set([\"Season\", \"playerID\", \"Team\", \"name\", \"next_Team\", \"Pos\"]))] = np.nan\n",
    "df_offense_2019[\"Season\"] = df_offense_2019[\"Season\"] + 1\n",
    "df_offense_2019[\"prev_Team\"] = df_offense_2019[\"Team\"]\n",
    "df_offense_2019[\"Team\"] = df_offense_2019[\"next_Team\"]\n",
    "\n",
    "df_offense = df_offense.append(df_offense_2019)\n",
    "#df_offense = df_offense.dropna(axis = 0)\n",
    "\n",
    "df_total_offense = df_offense.groupby([\"next_Season\", \"next_Team\"])[relevant_prev_columns].apply(lambda x: x.sum()).reset_index()\n",
    "\n",
    "off_columns_numeric.append('playerID')\n",
    "off_columns_numeric.append('next_Season')\n",
    "\n",
    "player_prev_merge_cols = off_columns_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_columns_sched2019 = [\"Week\", \"VisTm\", \"HomeTm\"]\n",
    "\n",
    "df_sched2019 = pd.read_csv(\"profootballref_schedule.csv\", usecols = relevant_columns_sched2019)\n",
    "df_sched2019 = df_sched2019.loc[~df_sched2019.Week.str.contains(\"Pre\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sched2019 = pd.merge(pd.merge(df_sched2019, df_abbreviations, left_on = \"VisTm\", right_on = \"Tm\").drop([\"VisTm\", \"Tm\"],\n",
    "                                                                                                          axis = 1),\n",
    "         df_abbreviations,\n",
    "        left_on = \"HomeTm\",\n",
    "        right_on = \"Tm\")[[\"Team_x\", \"Team_y\"]]\n",
    "\n",
    "df_sched2019 = df_sched2019.append(df_sched2019.rename({\"Team_x\": \"Team_y\", \"Team_y\": \"Team_x\"}))\n",
    "\n",
    "df_sched2019.rename({\"Team_x\": \"opp\", \"Team_y\": \"Team\"})\n",
    "\n",
    "df_sched2019.columns = [\"opp\", \"Team\"]\n",
    "\n",
    "df_sched2019[\"Season\"] = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_offense = pd.merge(df_offense, df_offense[player_prev_merge_cols], left_on = [\"playerID\", \"Season\"],\n",
    "                      right_on = [\"playerID\", \"next_Season\"],\n",
    "                     suffixes = [\"\", \"_player_prev\"])\n",
    "\n",
    "df_offense = pd.merge(df_offense, df_total_offense, left_on = [\"Team\", \"Season\"], right_on = [\"next_Team\", \"next_Season\"],\n",
    "                     suffixes = [\"\", \"_new_Team_prev\"])\n",
    "\n",
    "df_offense = pd.merge(df_offense, df_total_offense, left_on = [\"prev_Team\", \"Season\"], right_on = [\"next_Team\", \"next_Season\"],\n",
    "                     suffixes = [\"\", \"_old_Team_prev\"])\n",
    "\n",
    "for col in relevant_prev_columns:\n",
    "    df_offense[col + \"_Team_prev_delta\"] = df_offense[col + \"_new_Team_prev\"] - df_offense[col + \"_old_Team_prev\"]\n",
    "    \n",
    "    \n",
    "df_offense[\"exp\"] = df_offense.groupby(\"playerID\").Season.transform(lambda x: x - min(x))\n",
    "\n",
    "\n",
    "relevant_sched_columns  = off_columns_numeric_no_avg.copy()\n",
    "relevant_sched_columns.remove('points')\n",
    "\n",
    "\n",
    "df_sched = df_train.groupby([\"Season\", \"opp\"])[[\"Team\", \"game.id\"]].apply(lambda x: x.drop_duplicates(\"game.id\")).reset_index().drop([\"level_2\", \"game.id\"], axis = 1)\n",
    "\n",
    "df_prevSched =  pd.merge(df_sched,\n",
    "         (df_train.groupby([\"Season\", \"Team\"])[relevant_sched_columns].sum()/16).reset_index(),\n",
    "        left_on = [\"Season\", \"opp\"], right_on = [\"Season\", \"Team\"]).groupby([\"opp\",\"Season\"]).sum().reset_index()\n",
    " \n",
    "df_prevSched[\"Season\"] += 1    \n",
    "\n",
    "df_sched = df_sched.append(df_sched2019)\n",
    "\n",
    "df_sched.Season -= 1\n",
    "\n",
    "df_currSched =  pd.merge(df_sched,\n",
    "         (df_train.groupby([\"Season\", \"Team\"])[relevant_sched_columns].sum()/16).reset_index(),\n",
    "        left_on = [\"Season\", \"opp\"], right_on = [\"Season\", \"Team\"]).groupby([\"opp\",\"Season\"]).sum().reset_index()\n",
    " \n",
    "df_currSched[\"Season\"] += 1     \n",
    "\n",
    "df_offense = pd.merge(df_offense,\n",
    "                      df_prevSched,\n",
    "         left_on = [\"Team\", \"Season\"],\n",
    "         right_on = [\"opp\", \"Season\"],\n",
    "         suffixes = [\"\", \"_curr_sched\"])\n",
    "    \n",
    "    \n",
    "df_offense = pd.merge(df_offense, \n",
    "        df_currSched,\n",
    "         left_on = [\"prev_Team\", \"Season\"],\n",
    "         right_on = [\"opp\", \"Season\"],\n",
    "         suffixes = [\"\", \"_past_sched\"])\n",
    "\n",
    "df_defense = pd.merge(df_defense,\n",
    "                     df_currSched,\n",
    "         left_on = [\"Team\", \"Season\"],\n",
    "         right_on = [\"opp\", \"Season\"],\n",
    "         suffixes = [\"\", \"_curr_sched\"])\n",
    "\n",
    "df_defense = pd.merge(df_defense,\n",
    "                     df_prevSched,\n",
    "         left_on = [\"Team\", \"Season\"],\n",
    "         right_on = [\"opp\", \"Season\"],\n",
    "         suffixes = [\"\", \"_past_sched\"])\n",
    "\n",
    "for col in list(set(relevant_sched_columns) - set([\"Team\"])):\n",
    "    df_offense[col + \"_delta_sched\"] = df_offense[col + \"_past_sched\"] - df_offense[col + \"_curr_sched\"]\n",
    "    df_defense[col + \"_delta_sched\"] = df_defense[col + \"_past_sched\"] - df_defense[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Unnecessary Values for each Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_defense_scores.columns = [\"points\"]\n",
    "\n",
    "df_defense_scores = df_defense_scores[32:len(df_defense_scores)].reset_index(drop = True)\n",
    "\n",
    "df_defense_scores[\"Team\"] = df_defense[\"Team\"]\n",
    "df_defense_scores[\"Season\"] = df_defense[\"Season\"] - 1\n",
    "\n",
    "df_defense_scores_2018 = df_defense_scores.loc[df_defense_scores.Season == 2017]\n",
    "df_defense_scores_2018[\"Season\"] = df_defense_scores_2018[\"Season\"] + 1\n",
    "df_defense_scores_2018[\"points\"] = np.nan\n",
    "\n",
    "df_defense_scores = df_defense_scores.append(df_defense_scores_2018)\n",
    "\n",
    "df_defense = pd.merge(df_defense, df_defense_scores, on = [\"Season\", \"Team\"],suffixes = [\"_prev\", \"\"])\n",
    "\n",
    "\n",
    "\n",
    "df_offense['exp_keep'] = df_offense.exp\n",
    "df_offense['pos_keep'] = df_offense.Pos\n",
    "df_offense = pd.get_dummies(df_offense, columns = [\"exp\",\"Pos\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "off_columns_numeric_no_avg_original = off_columns_numeric_no_avg.copy()\n",
    "\n",
    "for col in off_columns_numeric_no_avg_original:\n",
    "    off_columns_numeric_no_avg.append(col + '_per_game')\n",
    "    off_columns_numeric_no_avg.append(col + '_var')\n",
    "    off_columns_numeric_no_avg.append(col + '_career_per_game')\n",
    "    off_columns_numeric_no_avg.append(col + '_career')\n",
    "\n",
    "off_columns_numeric_no_avg.append('n_games')\n",
    "off_columns_numeric_no_avg.append('rush_per_att')\n",
    "off_columns_numeric_no_avg.append('pass_per_att')\n",
    "off_columns_numeric_no_avg.append('rec_per_att')\n",
    "off_columns_numeric_no_avg.append('pass_per_comp')\n",
    "off_columns_numeric_no_avg.append('rush_per_att')\n",
    "off_columns_numeric_no_avg.append('td_pass_per_att')\n",
    "off_columns_numeric_no_avg.append('td_pass_per_comp')\n",
    "off_columns_numeric_no_avg.append('td_rec_per_att')\n",
    "off_columns_numeric_no_avg.append('fumb_rush_per_att')\n",
    "off_columns_numeric_no_avg.append('fumb_pass_per_att')\n",
    "off_columns_numeric_no_avg.append('int_pass_per_att')\n",
    "off_columns_numeric_no_avg.append('fumb_per_rec')\n",
    "off_columns_numeric_no_avg.append('name_dict')\n",
    "off_columns_numeric_no_avg.append('next_Team')\n",
    "off_columns_numeric_no_avg.append('prev_Team')\n",
    "off_columns_numeric_no_avg.append('next_Season')\n",
    "off_columns_numeric_no_avg.append('points_per_game')\n",
    "\n",
    "off_columns_numeric_no_avg.remove('points')\n",
    "off_columns_numeric_no_avg.append('opp')\n",
    "\n",
    "df_offense = df_offense.drop(off_columns_numeric_no_avg, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_offense_train = df_offense.loc[~df_offense.points.isna()]\n",
    "df_offense_hold = df_offense.loc[df_offense.points.isna()]\n",
    "\n",
    "df_defense_train = df_defense.loc[~df_defense.points.isna()]\n",
    "df_defense_hold = df_defense.loc[df_defense.points.isna()]\n",
    "\n",
    "X_train_O = df_offense_train.drop(\"points\", axis = 1)\n",
    "y_train_O = df_offense_train[\"points\"]\n",
    "\n",
    "X_train_D = df_defense_train.drop(\"points\", axis = 1)\n",
    "y_train_D = df_defense_train[\"points\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(actual, predict):\n",
    "\n",
    "    return sum(abs(actual - predict))/len(predict)\n",
    "\n",
    "mse_score = make_scorer(mse, greater_is_better = False)\n",
    "\n",
    "def featureModelSelection(X_train, y_train, Pos):\n",
    "    f = open('results_' + Pos + '.txt', 'w')\n",
    "    \n",
    "    X_train = X_train.select_dtypes(exclude = object)\n",
    "\n",
    "\n",
    "    models = [LinearRegression(), Ridge(), Lasso(), XGBRegressor(objective = 'reg:squarederror'), \n",
    "          RandomForestRegressor()]\n",
    "    \n",
    "    params = [[{\"fit_intercept\" : [True]}], \n",
    "              [{\"alpha\": [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]}],\n",
    "             [{\"alpha\": [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]}],\n",
    "             [{\"n_estimators\": [5, 10, 50, 100, 200], \"max_depth\": [3, 4, 5, 6, 7, 8]}],\n",
    "             [{\"n_estimators\": [5, 10, 50, 100, 200], \"max_depth\": [3, 4, 5, 6, 7, 8]}]]\n",
    "    \n",
    "    for m in range(len(models)):\n",
    "        \n",
    "        gs = GridSearchCV(models[m], params[m], n_jobs = -1, scoring = mse_score).fit( X_train, y_train)\n",
    "        \n",
    "        print(Pos)\n",
    "        print(\"\\nModel: \" + type(models[m]).__name__)\n",
    "        print(\"\\nScore: \" + str(gs.best_score_))\n",
    "        print(\"\\nParams: \" + str(gs.best_params_))\n",
    "        print('\\n')\n",
    "        print('---------------------------------------------')\n",
    "        print('\\n')\n",
    "\n",
    "        \n",
    "        \n",
    "        print(Pos, file = f)\n",
    "        print(\"\\nModel: \" + type(models[m]).__name__, file =f )\n",
    "        print(\"\\nScore: \" + str(gs.best_score_), file = f)\n",
    "        print(\"\\nParams: \" + str(gs.best_params_), file = f)\n",
    "        print('\\n', file = f)\n",
    "        print('---------------------------------------------', file = f)\n",
    "        print('\\n', file = f)\n",
    "        \n",
    "\n",
    "    \n",
    "    f.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O_NonPPR\n",
      "\n",
      "Model: LinearRegression\n",
      "\n",
      "Score: -54.04958052289569\n",
      "\n",
      "Params: {'fit_intercept': True}\n",
      "\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "O_NonPPR\n",
      "\n",
      "Model: Ridge\n",
      "\n",
      "Score: -25.256431180324476\n",
      "\n",
      "Params: {'alpha': 10000}\n",
      "\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "O_NonPPR\n",
      "\n",
      "Model: Lasso\n",
      "\n",
      "Score: -23.292635582161434\n",
      "\n",
      "Params: {'alpha': 10}\n",
      "\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "O_NonPPR\n",
      "\n",
      "Model: XGBRegressor\n",
      "\n",
      "Score: -24.369373657578258\n",
      "\n",
      "Params: {'max_depth': 5, 'n_estimators': 200}\n",
      "\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "O_NonPPR\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "\n",
      "Score: -28.874647654893984\n",
      "\n",
      "Params: {'max_depth': 8, 'n_estimators': 200}\n",
      "\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "D\n",
      "\n",
      "Model: LinearRegression\n",
      "\n",
      "Score: -35.6965754032135\n",
      "\n",
      "Params: {'fit_intercept': True}\n",
      "\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "D\n",
      "\n",
      "Model: Ridge\n",
      "\n",
      "Score: -29.012994462291793\n",
      "\n",
      "Params: {'alpha': 1000}\n",
      "\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "D\n",
      "\n",
      "Model: Lasso\n",
      "\n",
      "Score: -28.939561564757486\n",
      "\n",
      "Params: {'alpha': 10000}\n",
      "\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "D\n",
      "\n",
      "Model: XGBRegressor\n",
      "\n",
      "Score: -28.683861911296844\n",
      "\n",
      "Params: {'max_depth': 3, 'n_estimators': 50}\n",
      "\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "D\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "\n",
      "Score: -27.43821486627197\n",
      "\n",
      "Params: {'max_depth': 4, 'n_estimators': 100}\n",
      "\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featureModelSelection(X_train_O, y_train_O, 'O_NonPPR') \n",
    "featureModelSelection(X_train_D, y_train_D, 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_O = Lasso(alpha = 10).fit(X_train_O.dropna().select_dtypes(exclude = object),\n",
    "                                                                      y_train_O.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['total_games', 'passyds_player_prev', 'rushyds_player_prev',\n",
       "       'recyds_player_prev', 'kickret.avg_player_prev',\n",
       "       'puntret.avg_player_prev', 'fgyds_player_prev', 'points_player_prev',\n",
       "       'pass.att_var_player_prev', 'pass.comp_var_player_prev',\n",
       "       ...\n",
       "       'kickret.avg_curr_sched', 'puntret.avg_curr_sched',\n",
       "       'pass.att_past_sched', 'passyds_past_sched', 'kickret.avg_past_sched',\n",
       "       'fgyds_past_sched', 'passyds_delta_sched', 'rush.att_delta_sched',\n",
       "       'fgyds_delta_sched', 'rushyds_delta_sched'],\n",
       "      dtype='object', length=119)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_O.dropna().select_dtypes(exclude = object).columns[model_O.coef_ != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00,  5.72576117e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  4.81373801e-03,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  2.03927115e-02,\n",
       "        0.00000000e+00,  1.90207738e-02, -0.00000000e+00, -0.00000000e+00,\n",
       "       -4.65190135e-02,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -5.36722307e-02, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  3.61049949e-02,\n",
       "        0.00000000e+00, -0.00000000e+00,  1.60865729e-01,  0.00000000e+00,\n",
       "        3.31947764e-04,  0.00000000e+00, -6.28051150e-04,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  3.71333551e-02,\n",
       "       -1.64505273e-05,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -3.52463762e-04,  2.41508493e-02,\n",
       "        8.22518579e-06,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        2.17648424e-05, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -4.01873351e-04,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -4.46282264e-03, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -2.60976961e-04,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  1.11012535e-02, -0.00000000e+00,\n",
       "       -5.96371083e+00, -0.00000000e+00,  0.00000000e+00,  1.05624427e-02,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  2.27243052e-03,  9.71561098e-02, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  7.73942663e-03,\n",
       "        0.00000000e+00, -0.00000000e+00,  2.67696475e-01,  0.00000000e+00,\n",
       "        0.00000000e+00,  4.97841990e-03,  1.53645101e-01, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  6.92794742e-03,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  1.94305048e-02,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  1.80921584e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -7.44868388e-02,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -4.20659634e-03,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.62198600e-04,\n",
       "       -0.00000000e+00,  0.00000000e+00,  2.97313967e-03, -1.45508475e-03,\n",
       "        0.00000000e+00, -1.75619372e-03, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        1.03881165e-03,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -9.23467401e-05, -0.00000000e+00, -1.73550054e-05,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        1.22449487e-06, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -8.76645473e-05,  3.81788624e-04,\n",
       "       -1.93992900e-05,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -6.77370437e-06, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -2.83761469e-03,  0.00000000e+00,  8.87663113e-05,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -1.97489179e-02,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -5.51687857e-04,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -1.51409724e-02,  0.00000000e+00,\n",
       "        9.45349285e-06,  0.00000000e+00,  3.11918221e-03,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  4.90762115e-04, -0.00000000e+00,\n",
       "        1.14246530e-02, -1.79013857e-03,  0.00000000e+00,  3.48666232e-03,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.01817032e-02,\n",
       "        0.00000000e+00, -1.57012296e-03,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -2.58353575e-05, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  1.20755162e-02,  0.00000000e+00,  6.31452423e-04,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  4.53418486e-03,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -6.29643453e-03,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -7.28839101e-03,\n",
       "        0.00000000e+00, -0.00000000e+00,  1.22527207e-03,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -5.36886729e-03,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -4.25894354e-04, -0.00000000e+00,\n",
       "        0.00000000e+00,  4.34645401e-03, -0.00000000e+00, -9.79953923e-05,\n",
       "       -0.00000000e+00, -1.46163708e-04,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -1.26473183e-02,  2.14348013e-06,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -1.72395236e-04,  0.00000000e+00,  5.01741413e-06,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -5.57148042e-07,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -1.74694682e-07,\n",
       "        0.00000000e+00,  1.67830590e-05,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -2.80746557e-05,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  1.58364821e-04, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        2.76695197e-04,  7.84110658e-03, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  7.36283956e-03,  0.00000000e+00,\n",
       "       -1.71445217e-03,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -4.86104959e-05, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        1.20725092e-02, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        2.87728752e-03,  0.00000000e+00, -1.75792929e-02, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -1.98029341e-03, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -2.26652070e-03,  0.00000000e+00, -4.64229064e-04, -0.00000000e+00,\n",
       "        0.00000000e+00,  1.86999754e-03,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        3.90188092e-04, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  1.49240600e-06,  0.00000000e+00,  1.92883129e-04,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -1.23640979e-06, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  5.20720479e-04,\n",
       "        0.00000000e+00, -3.21260542e-05,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  7.19544768e-06, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  5.26585539e-03,  0.00000000e+00, -1.55267586e-04,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  7.18307369e-06,  0.00000000e+00,  2.15210767e-03,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -1.04218808e-05,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -4.78638161e-04,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  4.40937849e-04,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  4.24204307e-04,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        2.25234326e-05,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -3.11330785e-05,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -8.30758125e-04,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  3.63664847e-05,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  9.79070529e-03,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -5.58565384e-04, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -8.06691593e-04,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00,  1.46731123e-02, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -1.58301703e-03,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -8.26267553e-04,  0.00000000e+00, -0.00000000e+00, -1.67455982e-02,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -1.64609745e-02, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -4.97282086e-04, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_O.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 719)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-bc76bd7377b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m df_results_O = pd.DataFrame(data = model_O.predict(\n\u001b[1;32m----> 5\u001b[1;33m     df_offense_hold.select_dtypes(exclude = object).drop('points', axis = 1).dropna()), columns = ['points'])                                                   \n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mdf_results_O\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_offense_hold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdf_results_O\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Team'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_offense_hold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTeam\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m         \"\"\"\n\u001b[1;32m--> 213\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    803\u001b[0m                                    dense_output=True) + self.intercept_\n\u001b[0;32m    804\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 805\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mElasticNet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"coef_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[0;32m    198\u001b[0m                                dense_output=True) + self.intercept_\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    580\u001b[0m                              \u001b[1;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m                              % (n_samples, shape_repr, ensure_min_samples,\n\u001b[1;32m--> 582\u001b[1;33m                                 context))\n\u001b[0m\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 719)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "model_O = Lasso(alpha = 10).fit(X_train_O.dropna().select_dtypes(exclude = object),\n",
    "                                                                      y_train_O.dropna())\n",
    "                                                      \n",
    "df_results_O = pd.DataFrame(data = model_O.predict(\n",
    "    df_offense_hold.select_dtypes(exclude = object).drop('points', axis = 1).dropna()), columns = ['points'])                                                   \n",
    "df_results_O['name'] = df_offense_hold.reset_index().name\n",
    "df_results_O['Team'] = df_offense_hold.reset_index().Team\n",
    "df_results_O['Pos'] = df_offense_hold.reset_index().pos_keep\n",
    "                                                      \n",
    "model_D = Ridge(alpha = 1000).fit(X_train_D.drop([\"Team\", \"opp\", \"opp_past_sched\"], axis = 1), y_train_D)\n",
    "                                       \n",
    "                                                      \n",
    "df_results_D = pd.DataFrame(data = model_D.predict(df_defense_hold.drop([\"Team\", \"opp\", \"opp_past_sched\", 'points'], axis = 1)),\n",
    "columns = ['points'])                                            \n",
    "df_results_D['name'] = df_defense_hold.reset_index().Team + '_DEF'\n",
    "df_results_D['Pos'] = \"DEF\"\n",
    "df_results_D['Team'] = df_defense_hold.reset_index().Team\n",
    "\n",
    "df_results = df_results_O.append(df_results_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results['rank_val'] = df_results.groupby(\"Pos\").points.transform(lambda x: x.rank(ascending = False))\n",
    "\n",
    "df_results.drop(df_results.loc[(df_results.rank_val > 30) & (df_results.Pos == \"QB\")].index, inplace = True)\n",
    "df_results.reset_index(inplace = True, drop = True)\n",
    "df_results.drop(df_results.loc[(df_results.rank_val > 50) & (df_results.Pos == \"RB\")].index, inplace = True)\n",
    "df_results.reset_index(inplace = True, drop = True)\n",
    "df_results.drop(df_results.loc[(df_results.rank_val > 50) & (df_results.Pos == \"WR\")].index, inplace = True)\n",
    "df_results.reset_index(inplace = True, drop = True)\n",
    "df_results.drop(df_results.loc[(df_results.rank_val > 25) & (df_results.Pos == \"TE\")].index, inplace = True)\n",
    "df_results.reset_index(inplace = True, drop = True)\n",
    "df_results.drop(df_results.loc[(df_results.rank_val > 15) & (df_results.Pos == \"K\")].index, inplace = True)\n",
    "df_results.reset_index(inplace = True, drop = True)\n",
    "df_results.drop(df_results.loc[(df_results.rank_val > 25) & (df_results.Pos == \"DEF\")].index, inplace = True)\n",
    "df_results.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results['points_abv_avg'] = df_results.groupby(\"Pos\").points.transform(lambda x: x - x.mean())\n",
    "\n",
    "df_results = df_results.sort_values('points_abv_avg', ascending = False)\n",
    "\n",
    "df_results[['name', 'Pos', 'Team', 'points_abv_avg']].to_csv('order_nonPPR.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
